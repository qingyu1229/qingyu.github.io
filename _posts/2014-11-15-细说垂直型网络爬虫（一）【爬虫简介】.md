---
layout: post
title: 细说垂直型网络爬虫（一）【爬虫简介】
category: 细说垂直型网络爬虫
date: 2014-11-15
---



#  细说垂直型网络爬虫（一）【爬虫简介】

标签： 网络爬虫


##一、什么是垂直型网络爬虫
只抓取某一类或某几类的网站的网络爬虫。

##二、网络爬虫的工作原理
>
1. 给爬虫一个种子URL。
2. 获取页面内容并存储，抽取页面中的URL。
3. 将新获取到的URL加入到URL队列中，等待处理。
4. 从URL队列中获取一个URL然后重复步骤2。

注意：为了防止爬虫无限制的抓取下去，通常会对抓取的深度、抓起与的页面数或者抓取时间做一些限制。

<!-- more -->

##三、垂直型网络爬虫需要注意的几个地方

###抓取方式的选择：
>
- 全网抓取：抓取目标网站的所有页面，这种方式的可以获取到最大量的信息，但是抓取效率不高，耗时太长，容易被目标网站封IP。
- 半全网抓取：鉴于全网抓取的效率底的问题，我们可以只抓取部分网页。通常不同类型的页面URL有不同的规律，我们可以只抓取URL规则符合某些规则的页面。
- 定向抓取：半全网抓取虽然符合了基本需求，但是通常我们的服务器的资源是有限的，怎样最高效的利用这些有用的资源呢？还可不可以抓取更加少量的页面呢？办法总比问题多，
在选择入口URL的时候，我们可以选取目标页面（也就是包含有我们需要的信息的页面）父级页面（通常是列表页），然后将抓取深度定为1，这样就可以充分利用资源去抓取我们需
要的信息了，但是，这种方法需要比较多的人工干预。
以上就是几种常见的垂直抓取方法了，依据不同的需求选择不同的抓取方法。

###数据结构化：
>
垂直抓取通常需要将网页中的信息结构化，存储到数据库或建立索引等。但是网页通常都是不规则的，怎么办？

- 通用抽取方法（具体解决方案我在后面的博客中会介绍）：既然是垂直抓取，那么需要抓取的这一类网站一般还是有共同的规则的。利用共同的规则写一个通用的抽取方法。
- 为每个网站都配置抽取方法：一般同一个网站的目标页面结构都一样， 为每个网站都配置一个抽取方法。

什么？用什么工具抽取？
Jsoup、HtmlCleaner……

###被限制访问：
>
如果你抓取某个网站太快的话，你可能会被禁止访问。怎么办？抓取速度放慢一点吧，或者使用代理。

###监控：
>
程序运行过程中总汇出现一些意外，怎么办呢？当然是再写程序来监控啦，难道你要一直看着程序运行吗？

- 爬虫程序的监控：常见的方法有心跳检测，也就是每隔一段时间检查一下爬虫程序是不是还在正常运行，不是的话就重新启动它。如果想要更加详细的信息的话，可以加入JMX，
监控几个抓取过程中重要的变量。
- 目标网站的监控：如果目标网站屏蔽了你的IP，或者目标网站改版了，或者他的服务器挂了……，爬虫是抓不回来数据的，于是就需要一个监控这些网站的程序，当发现这些“异常”
的时候，就可以考虑，暂时不抓取这个网站了。
- 抓取信息的监控：额，说“监控”其实不太准确。这个环节主要是对抓取到的信息的一个检测，防止抓取到的信息出现乱码或其他不可预测的“异常”。





