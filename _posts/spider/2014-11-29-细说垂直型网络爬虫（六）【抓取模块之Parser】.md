---
layout: post
title: 细说垂直型网络爬虫（六）【抓取模块之Parser】
category: 细说垂直型网络爬虫
date: 2014-11-29

---

#细说垂直型网络爬虫（六）【抓取模块之Parser】

标签： 网络爬虫 抓取模块 解析 Parser


##解析（Parser）的主要方法
解析一个网页主要的方法有三种：正则匹配、Document结构树处理、智能算法提取。

<!-- more -->
>
- 1.正则匹配可以很精确的抽取到需要的数据，但是正则匹配对于书写正则表达式的要求较高，在实际项目中不利于理解阅读和传播。
- 2.Document结构树处理主要的处理的代表有Jsoup的CssPath抽取和HTMLClear的Xpath，这两种方法依旧比较复杂，但是相比于正则，一
般的开发人员可以很容易的编写出抽取的“Path”。（PS:在一些浏览器中的审查元素的窗口中可以直接copy css Path和Xpath）
![审查元素copyPath](/res/img/blogimg/copyPath.png)
- 3.智能提取一般应用于对于数据结构化要求不是特别高的Spider中，例如需要将一些新闻抓取后用Lucene存储，并不需要结构化为具体
的新闻时间、新闻标题时。

下面主要介绍利用Document结构树进行数据的结构化（智能提取后面会有介绍）

##解析的主要流程
以下是一套依据具体项目的需求抽象出来的提取流程：
>
- 1.Create出网页的Document，移除影响定位目标元素的Elements；
- 2.定位出目标信息的Element，暂且命名为DataElement；
- 3.去除DataElement中的杂质Element。
- 4.处理DataElement中需要处理的多媒体信息。
- 5.将DataElement格式化为String，利用字符串的各种操作再次去除一些杂质。
- 6.将上一步中得到的String再包装为Element。

以上的提取流程是一个网页新闻抓取的项目的抽取流程，其他的项目可以依据自己的需求进行一些增加和删减。

##解析规则的统一
垂直抓取通常都不是只抓取一个网站或一个网站的一个模块。由于不同的网站的结构不一样，于是就可能出现很多的抽取规则。那么如何
管理这些抽取规则呢？
















